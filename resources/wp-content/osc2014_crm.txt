### Cluster Option ###
property no-quorum-policy="ignore" \
        stonith-enabled="true" \
        startup-fencing="false"

### Resource Defaults ###
rsc_defaults resource-stickiness="INFINITY" \
        migration-threshold="1"

### Group Configuration ###
group grpTrac \
        prmFS \
        prmVIP \
        prmDB \
        prmWEB

### Clone Configuration ###
clone clnPing \
        prmPing

clone clnDiskd1 \
        prmDiskd1

clone clnDiskd2 \
        prmDiskd2

#### Group Configuration ###
#group grpStonith1 \
#        prmStonith1
#
#group grpStonith2 \
#        prmStonith2

### Master/Slave Configuration ###

### Fencing Topology ###
fencing_topology \
        server01: prmStonith1 \
        server02: prmStonith2

### Primitive Configuration ###
primitive prmFS ocf:heartbeat:Filesystem \
        params \
                fstype="ext4" \
                run_fsck="force" \
                device="/dev/vdb1" \
                options="barrier=0" \
                directory="/pgsqldb" \
        op start interval="0s" timeout="60s" on-fail="restart" \
        op monitor interval="10s" timeout="60s" on-fail="restart" \
        op stop interval="0s" timeout="60s" on-fail="fence"

primitive prmVIP ocf:heartbeat:IPaddr2 \
        params \
                ip="192.168.1.100" \
                nic="eth3" \
                cidr_netmask="24" \
        op start interval="0s" timeout="60s" on-fail="restart" \
        op monitor interval="10s" timeout="60s" on-fail="restart" \
        op stop interval="0s" timeout="60s" on-fail="fence"

primitive prmDB ocf:heartbeat:pgsql \
        params \
                pgctl="/usr/pgsql-9.3/bin/pg_ctl" \
                psql="/usr/pgsql-9.3/bin/psql" \
                pgdata="/pgsqldb/data" \
                start_opt="-p 5432" \
                pgdba="postgres" \
                pgport="5432" \
                pgdb="template1" \
        op start interval="0s" timeout="300s" on-fail="restart" \
        op monitor interval="10s" timeout="60s" on-fail="restart" \
        op stop interval="0s" timeout="300s" on-fail="fence"

primitive prmWEB ocf:heartbeat:apache \
        op start interval="0s" timeout="300s" on-fail="restart" \
        op monitor interval="10s" timeout="60s" on-fail="restart" \
        op stop interval="0s" timeout="300s" on-fail="fence"

primitive prmPing ocf:pacemaker:ping \
        params \
                name="default_ping_set" \
                host_list="192.168.1.1" \
                multiplier="100" \
                attempts="2" \
                timeout="2" \
                debug="true" \
        op start interval="0s" timeout="60s" on-fail="restart" \
        op monitor interval="10s" timeout="60s" on-fail="restart" \
        op stop interval="0s" timeout="60s" on-fail="ignore"

primitive prmDiskd1 ocf:pacemaker:diskd \
        params \
                name="diskcheck_status" \
                device="/dev/vdb" \
                options="-e -t 70" \
                interval="10" \
                dampen="2" \
        op start interval="0s" timeout="60s" on-fail="restart" \
        op monitor interval="10s" timeout="60s" on-fail="restart" \
        op stop interval="0s" timeout="60s" on-fail="ignore"

primitive prmDiskd2 ocf:pacemaker:diskd \
        params \
                name="diskcheck_status_internal" \
                device="/dev/vda" \
                options="-e" \
                interval="10" \
                dampen="2" \
        op start interval="0s" timeout="60s" on-fail="restart" \
        op monitor interval="10s" timeout="60s" on-fail="restart" \
        op stop interval="0s" timeout="60s" on-fail="ignore"

primitive prmStonith1 stonith:external/libvirt \
        params \
                pcmk_reboot_timeout="60s" \
                hostlist="server01" \
                hypervisor_uri="qemu+ssh://192.168.122.1/system" \
        op start interval="0s" timeout="60s" on-fail="restart" \
        op monitor interval="3600s" timeout="60s" on-fail="restart" \
        op stop interval="0s" timeout="60s" on-fail="ignore"

primitive prmStonith2 stonith:external/libvirt \
        params \
                pcmk_reboot_timeout="60s" \
                hostlist="server02" \
                hypervisor_uri="qemu+ssh://192.168.122.1/system" \
        op start interval="0s" timeout="60s" on-fail="restart" \
        op monitor interval="3600s" timeout="60s" on-fail="restart" \
        op stop interval="0s" timeout="60s" on-fail="ignore"

### Resource Location ###
location rsc_location-grpTrac-1 grpTrac \
        rule 200: #uname eq server01 \
        rule 100: #uname eq server02 \
        rule -INFINITY: not_defined default_ping_set or default_ping_set lt 100 \
        rule -INFINITY: not_defined diskcheck_status or diskcheck_status eq ERROR \
        rule -INFINITY: not_defined diskcheck_status_internal or diskcheck_status_internal eq ERROR
location rsc_location-prmStonith1 prmStonith1 \
        rule -INFINITY: #uname eq server01
location rsc_location-prmStonith2 prmStonith2 \
        rule -INFINITY: #uname eq server02

### Resource Colocation ###
colocation rsc_colocation-grpTrac-clnPing-1 INFINITY: grpTrac clnPing
colocation rsc_colocation-grpTrac-clnDiskd1-2 INFINITY: grpTrac clnDiskd1
colocation rsc_colocation-grpTrac-clnDiskd2-3 INFINITY: grpTrac clnDiskd2

### Resource Order ###
order rsc_order-clnPing-grpTrac-1 0: clnPing grpTrac symmetrical=false
order rsc_order-clnDiskd1-grpTrac-2 0: clnDiskd1 grpTrac symmetrical=false
order rsc_order-clnDiskd2-grpTrac-3 0: clnDiskd2 grpTrac symmetrical=false

